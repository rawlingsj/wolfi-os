package:
  name: spark
  version: 3.5.1
  epoch: 0
  description: Unified engine for large-scale data analytics
  copyright:
    - license: Apache-2.0
  dependencies:
    runtime:
      - bash
      - openjdk-8-default-jvm
      - openjdk-8-jre

environment:
  contents:
    packages:
      - R
      - R-dev
      - bash
      - busybox
      - ca-certificates-bundle
      - curl
      - glibc-iconv
      - glibc-locale-en
      - grep
      - maven
      - openjdk-8
      - openjdk-8-default-jvm
      - perl-utils
      - procps
      - py3.11-pip
      - python-3.11
      - wolfi-base
      - wolfi-baselayout
      - yaml-dev
  environment:
    LANG: en_US.UTF-8
    JAVA_HOME: /usr/lib/jvm/java-1.8-openjdk

pipeline:
  - uses: git-checkout
    with:
      repository: https://github.com/apache/spark
      tag: v${{package.version}}
      expected-commit: fd86f85e181fc2dc0f50a096855acf83a6cc5d9c

  - uses: patch
    with:
      patches: make-distribution.patch bump-packages.patch

  - runs: |
      ./dev/make-distribution.sh --name custom-spark --pip -Psparkr -Phive -Phive-thriftserver -Pmesos -Pyarn -Pkubernetes

      patch dist/bin/load-spark-env.sh load-spark-env.sh.diff
      patch dist/sbin/spark-daemon.sh spark-daemon.sh.diff

      mkdir -p ${{targets.destdir}}/usr/lib/spark
      mv dist/* ${{targets.destdir}}/usr/lib/spark/

subpackages:
  - name: spark-compat
    description: "Compatibility package to place binaries in the location expected by upstream image"
    pipeline:
      - runs: |
          mkdir -p "${{targets.subpkgdir}}"/opt/
          ln -s /usr/lib/spark/ ${{targets.subpkgdir}}/opt/spark
      - uses: strip

  - name: spark-minimal
    description: Minimal version of Spark
    pipeline:
      - runs: |
          ./dev/make-distribution.sh --name minimal-spark --pip -Psparkr -Phive

          mkdir -p ${{targets.contextdir}}/usr/lib/spark
          mv dist/* ${{targets.contextdir}}/usr/lib/spark/

update:
  enabled: true
  github:
    identifier: apache/spark
    use-tag: true
    strip-prefix: v

test:
  pipeline:
    - runs: |
        /usr/lib/spark/bin/spark-submit --version
